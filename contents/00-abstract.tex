
%We consider the task of predicting the pose of a person moving in front of a drone, using the input images coming from an on-board camera. We aim to improve the generalization capabilities of a machine learning model designed for this intent.

We consider the task of predicting the pose of a person moving in front of a drone, using the input images coming from an on-board camera. We aim to improve a machine learning model designed for this intent \cite{mantegazza2019visionbased}. The approach relies on supervised learning to perform a regression on the user's pose through a Residual Neural Network. The training data is collected in a dedicated drone arena, using a Motion Capture system to acquire the ground truth. The prototype achieves good performance inside the arena but cannot fulfill its duty in unknown environments.

First, we understand the main issues of the learned task through network interpretation. Applying Grad-CAM, we observe that the model not only focus on the user who is actually facing the droneâ€™s camera. Instead, various portions of the input images are considered when the model makes its predictions. We assume that the neural network has undesirably learned some details about the drone arena in which the dataset has been collected.

As a solution, we develop an advanced data augmentation technique designed for
%enhanching the generalization capabilities of the model, by
breaking the relationship between the model's learning and the training room. Our approach makes use of Mask R-CNN for computing the user's mask from each sample in the original training set. Then, we use the computed masks for replacing the corresponding images' background and retraining the neural network.

We run experiments that show that our proposal is successful both from quantitative and qualitative viewpoints. The model, trained on the augmented dataset, produces satisfactory results in a large variety of real-world scenarios.