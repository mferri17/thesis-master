\chapter{Model Implementation}
\label{chap:implementation}

In this chapter, we explain how the proposed solution has been implemented.

Firstly, we focus on the implementation of our generalization strategy, mainly concerning the way the dataset is treated and processed to reduce overfitting. Then, Section \ref{sec:model-variants} provides three model alternatives that will be considered for evaluation and comparison in Chapter \ref{chap:evaluation}. Finally, we provide technical details about the training procedure, with a particular focus on timing performance. 




\section{Background Replacement}
\label{sec:implementation-bgreplace}

As demonstrated in Section \ref{subsec:gradcam-results}, the approach defined by Mantegazza et al. \cite{mantegazza2019visionbased} is lacking generalization capabilities. The main reason behind this problem is attributable to its dataset composition. More specifically, the model is biased by many elements appearing in the drone arena, in which the data have been originally collected. To eliminate the problem, we modify the training set by performing background replacement on its images.

In Section \ref{subsec:masking-maskrcnn}, we anticipated the use of Mask R-CNN to pre-process the dataset. The algorithm detects and creates a mask for all the objects appearing in the input images, labeling each mask with the category to which the object belongs (e.g., person, TV, bike, car, etc.). However, for our purposes, we are only interested in the mask corresponding to the user who is actually facing the drone. Since it is always the nearest person to the drone's camera, its mask must be the one with the largest size among all people's masks found by Mask R-CNN.

\medskip

To perform the background replacement, the training procedure receives, for each sample, also the corresponding user's mask. This is used to distinguish the subject from the rest of the image and accordingly blend the camera's frame with another image, serving as the background. The ground truth remains unchanged, and this is the main advantage of our approach. We can simulate a dataset acquired in different environments without actually collecting it, which would otherwise require a dedicated \gls{mocap} system. Our method is fairly similar to domain randomization (Section \ref{subsec:domain-randomization}), a technique widely applied in robotics to train \gls{ml} models in simulated virtual environments.

By providing a considerable amount of images to use as backgrounds, the \gls{ml} model trained on the modified dataset should be able to actually ignore the background. The \gls{cnn}, instead, will hopefully learn the concept of a person to predict its position in any condition.

\medskip

For our work, we select the publicly available dataset \cite{cvpr09} for Indoor Scene Recognition presented during the 9th Conference on Computer Vision and Pattern Recognition (CVPR). The dataset contains a total of 15'620 images divided into 67 indoor categories. For our task, categorization is not actually needed, but it ensures a good variety of scenarios to present to the model. For shortness, in this thesis, the dataset will be referred to as \textit{CVPR}.

During training, each sample is assigned to a randomly chosen background from the CVPR dataset. Even though the background replacement is done on the fly, the combination of each input image with a background forms a brand new dataset. Using this data, we train the network from scratch, starting to learn considerably different features than before. Figure \ref{fig:bgreplace-example} shows a demonstration of the background replacement technique applied to the samples already presented in Figure \ref{fig:frontalnet-dataset-overview}. 

\vspace*{5ex}
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.98\textwidth]{"contents/images/05-bgreplace-overview"}
	\caption[Example of background replacement on the training set]{Example of background replacement on the training set}
	\label{fig:bgreplace-example}
\end{figure}
\clearpage




\section{Image Augmentation}
\label{sec:implementation-imgaug}

Data augmentation is a common technique for improving neural networks' ability to generalize their task on unknown data. Introduced in Section \ref{subsec:data-augmentation}, image augmentation is ubiquitously used with \gls{cnn}s for reducing overfitting on the training images by applying random transformations.

For implementing image augmentation, we choose Albumentations \cite{Buslaev_2020} due to its benchmarking performance\footnote{\url{https://github.com/albumentations-team/albumentations\#benchmarking-results}}. Albumentations is a state of the art Python library that allows the definition of custom sequences composed of many different geometric transformations. These are applied according to user-specified probabilities and intensities. The possibilities are limitless, and the resulting images might be very different from the originals.

\medskip

In our case, it is not possible to modify the ground truth according to affine transformations because the relationship between the person's position in the image and the ground is not known a priori. For this reason, spatial-level augmentations (see Section \ref{subsec:data-augmentation}) are not an option. Instead, we mainly apply pixel-level transformations. The only exception is horizontal flipping, which only requires inverting the \texttt{Y} coordinate in the ground truth. As explained in Section \ref{subsec:dataset-composition}, the \texttt{Y} coordinate represents the horizontal alignment of the user \gls{wrt} the drone. Figure \ref{fig:frontalnet-dataset-distribution-class}, in the previous chapter, shows a propensity for the user to be on the right-part of the images. For this reason, we decide to mirror the camera's frames horizontally with a probability of 50\%.

Figure \ref{fig:albumentation-example} provides an example of image augmentation applied both on original and background-augmented samples. Those results combine pixel-level transformations on brightness and contrast, multiplicative noise, channels manipulation, and rectangular dropouts.

\begin{figure}[!h]
	\begin{center}
		\begin{subfigure}[h]{0.49\textwidth}
			\centering
			\includegraphics[width=1\textwidth]{"contents/images/05-imgaug-example-1"}
		\end{subfigure}
		\hfill
		\begin{subfigure}[h]{0.49\textwidth}
			\centering
			\includegraphics[width=1\textwidth]{"contents/images/05-imgaug-example-2"}
		\end{subfigure}
	\end{center}
	\vspace{-0.5cm}
	\caption[Example of image augmentation with Albumentations]{Example of image augmentation with Albumentations}
	\label{fig:albumentation-example}
\end{figure}

The combination of different transformations composes a pipeline, whose time performance depends on custom choices and probabilities. Among all tested augmentations, most of them only require a maximum of 0.7 seconds to be applied on a set of 10'000 $60 \times 108$ images, while the most expensive ones take up to 12 seconds under the same conditions\footnote{Benchmarks (in seconds): InvertImg 0.2; ToGray 0.2; ChannelShuffle 0.3; ChannelDropout 0.4; Blur 0.5; RandomGamma 0.5; RandomBrightnessContrast 0.6; Solarize 0.6; Equalize 0.7; MotionBlur: 0.7; HueSaturation 1.5 sec; RGBShift 1.5 sec; CLAHE 3.5 sec; CoarseDropout 3.5 sec; MultiplicativeNoise 7 sec; GaussNoise 10 sec; ISONoise 12 sec}. Tests have been performed on a notebook equipped with an Intel Core i7-6700HQ CPU @ 2.60 GHz.

\medskip

The Albumentations pipeline adopted for our work is shown in Listing \ref{lst:albumentations}. It takes about 4 seconds to process 10'000 images and accepts a parameter \texttt{aug\_prob} to define the prior probability of actually applying the augmentations to an input image. Some examples of resulting images are available in Figure \ref{fig:albumentation-chosen}.

\vspace{0.1cm}
\begin{python}
augmenter = A.Compose([
	A.RandomBrightnessContrast(brightness_by_max=True, p=0.75),
	A.RandomGamma(p=0.5),
	A.CLAHE(p=0.05),
	A.Solarize(threshold=(200, 250), p=0.2),
	A.OneOf([
		A.Equalize(by_channels=False, p=0.5),
		A.Equalize(by_channels=True, p=0.5),
	], p=0.1),
	A.RGBShift(p=0.3),
	A.OneOf([
		A.ChannelDropout(fill_value=128, p=0.2),
		A.ChannelShuffle(p=0.8),
	], p=0.1),
	A.MultiplicativeNoise(per_channel, elementwise, p=0.05),
	A.CoarseDropout(holes=(20, 70), size=(1, 4), p=0.2),
	A.ToGray(p=0.05),
	A.InvertImg(p=0.05),
	A.OneOf([
		A.Blur(blur_limit=4, p=0.5),
		A.MotionBlur(blur_limit=6, p=0.5),
	], p=0.05),
], p=aug_prob)
\end{python}
\vspace{-0.5cm}
\begin{lstlisting}[frame=none,caption={Chosen Albumentations pipeline}, 
label=lst:albumentations]
\end{lstlisting}

Furthermore, adding noise to images can greatly help \gls{cnn}s on avoiding overfitting \cite{shorten2019augmentationsurvey}. For this reason, at the end of the pipeline, we also apply Perlin noise \cite{perlin-noise} with a probability of 20\%. Since noise generation is highly time-consuming, we pre-compute a set of textures to be used later. During training, one of the generated Perlin noises for each augmented sample is randomly chosen, cropped, flipped, and finally applied to the input image. Half of the time, the noise is multiplied uniformly on all channels to produce a grayscale texture, while the other half of the time is differentiated over the RGB channels. Figure \ref{fig:perlin-noise} illustrates both cases.

\begin{figure}[!h]
	\centering
	\includegraphics[width=1 \textwidth]{"contents/images/05-imgaug-chosen"}
	\caption[Examples of the chosen image augmentation pipeline]{Examples of the chosen image augmentation pipeline}
	\label{fig:albumentation-chosen}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.75\textwidth]{"contents/images/05-imgaug-pelin"}
	\caption[Examples of Perlin noise]{Perlin noise example. From left to right: (1) randomly chosen, cropped and flipped 3-channels texture (2) applied uniformly (3) applied by channel}
	\label{fig:perlin-noise}
\end{figure}




\clearpage
\section{Models Definition}
\label{sec:model-variants}

We have defined the methodologies to perform background replacement and data augmentation on the original images. According to our work's objective, we are interested in the beneficial effects on generalization caused by background replacement.  These effects can be amplified when background replacement is combined with image augmentation. For this reason, we define three model alternatives to evaluate the validity of our solution. 

\begin{itemize}
    \item A baseline model, which is trained on the original dataset as-is (Section \ref{sec:dataset}), and corresponds to the exact approach proposed by Mantegazza et al. \cite{mantegazza2019visionbased}. Since it is trained with data coming directly from the drone arena, we call it the \texttt{Arena} model.
    \item A first variant of the model is defined by enabling background replacement only, without any other type of image augmentation. In this case, we replace original backgrounds (i.e., the drone arena) with randomly chosen images. For this purpose, we use the CVPR dataset presented in Section \ref{sec:implementation-bgreplace}, therefore we call this model \texttt{CVPR}.
    \item A second variant of the model includes both background replacement and image augmentation. This combination constitutes the most advanced model proposed in our thesis. For simplicity, it is called \texttt{CVPR Aug}.
\end{itemize}

The evaluation of the three models is described in Chapter \ref{chap:evaluation}.




\section{Data Generator}
\label{sec:data-generator}

This section focuses on the design and optimization of the data generator, which consists of retrieving and pre-processing the dataset before passing it to the \gls{cnn}.

For the implementation of the generator, we rely on the \texttt{tf.data} API \footnote{\url{https://www.tensorflow.org/guide/data}} provided by TensorFlow. The library allows the development of complex and modular input pipelines for transforming and iterate over the data in a highly-customizable way. Compared with other methods for managing the model's dataset, \texttt{tf.data} gives the possibility of optimizing its operations through asynchronous execution on the GPU. This optimization allows achieving the best possible performance by minimizing the total idle time\footnote{Idle time refers to the time wasted on waiting for input or resources, thus without actual training activities}.



\subsection{Basic Functioning}
\label{subsec:data-generator-basic}

The input pipeline always starts from the retrieval of the dataset. When working with a massive amount of data or when there is the need of augmenting a dataset online\footnote{In some cases, data augmentation can be previously performed to create a static augmented dataset. However, most of the time, augmentation is done during training.}, a common practice is to save each sample separately on disk. This method allows keeping in memory only the data required for a training step rather than the entire dataset. Otherwise, working with an extensive training set can lead to memory issues when using modest hardware.

We opt for this solution, and we split both training and test sets in 63'720 and 11'030 \texttt{pickle} files, respectively. Each sample contains the original image from the drone's camera, the ground truth according to the \gls{mocap} system, and the user's mask previously computed with Mask R-CNN.

\medskip

The generator only receives the entire list of file paths as input. On-demand, the samples are loaded using the \texttt{pickle} library, which unfortunately does not benefit from GPU acceleration. After a sample is loaded, it passes through the augmentation pipeline. In our case, it includes both background replacement and classic image augmentation. 

The former is done on every sample as long as a dataset for backgrounds has been provided to the data generator. The replacement is implemented with TensorFlow functions by blending the camera frame and the randomly chosen background using the relative user's mask. To speed up the process, all the background images from the given dataset are previously loaded in memory, already pre-processed to be compliant with input image shapes and types.

Data augmentation is applied according to a specified prior probability. It firstly calls the proper Albumentations pipeline defined in Listing \ref{lst:albumentations}. Being not implemented in native TensorFlow, it does not benefit from GPU optimization. After this image augmentation, the pipeline goes back to TensorFlow, performing horizontal flipping and adding Perlin noise\footnote{textures previously generated and randomly transformed, as explained in Section \ref{subsec:data-augmentation}}. 

Finally, the resulting image and its ground truth are processed to be passed as input to the neural network Keras model.



\subsection{Optimization}

Deep learning is incredibly time-consuming because many operations must be repeated a large number of times. Most of these operations regard the actual learning of the \gls{nn} parameters. However, also the input pipeline defined above can be responsible for a bottleneck in the process. In fact, during input operations, the model is not actually learning but only waiting for resources to be prepared.

If the input processing takes longer than actual training-related mathematical computations, then it is said that the program is highly input-bound. A good model should spend a tiny percentage of its total time waiting for input\footnote{a maximum of 5-10\% input time is considered acceptable} and a large majority of the time learning.

\medskip

The main causes of this issue are found in complex input pipelines. This due to pre-processing operations that are usually done on CPU rather than on GPU. This significantly increases the total time required for training. As described above, in our case, both data loading and image augmentation are implemented on the CPU. Furthermore, standard sequential computation requires the GPU to stop and wait for the input at every single mini-batch. This greatly reduces performance.

\texttt{tf.data} natively takes into account this problem and applies some automatic optimizations. This explains why the framework is preferred over the implementation of a data generator made in pure-Python. However, for better results, it is required to explicitly activate other optimizations provided by the library.

The following list provides a complete overview of the strategies adopted to reduce the GPU idle time. All of them are available through specific parameters shown in Section \ref{subsec:data-generator-code}.

\begin{itemize}
    \item \textit{Prefetching} decouples the moment when a data is produced from the time when it is actually used for computation. It is done by reading data ahead of the time they are requested, enabling the overlapping between input processing and training steps. The result is that total training time is the maximum time between input and computing time, rather than the sum.
    
    In our case, prefetching affects the entire input pipeline.
    
    \item \textit{Parallelization} allows parallelizing data transformation across multiple CPU cores, as much as the hardware is capable of. For example, a dual-core CPU can process two batches simultaneously, halving the total input time. 
    
    In our case, parallelization is enabled for the pre-processing part, mainly including background replacement and image augmentation.
    
    \item \textit{Caching} is used to store the dataset in memory or on local storage to prevent some operations from being executed for each epoch. Caching is particularly useful to avoid expensive data transformations or file opening.
    
    In our case, caching is applied on capable hardware just after the data loading procedure, which is responsible for reading files from the disk.
\end{itemize}




\clearpage
\subsection{Source Code}
\label{subsec:data-generator-code}

Listing \ref{lst:tfdata_generator} shows the pseudo-code for implementing the data generator as explained. It takes into account appropriate parameters for controlling data processing and performance optimization.

\vspace{0.2cm}
\begin{python}
def tfdata_generator(files, batch_size, 
                     bgs, aug_prob, noises,
                     prefetch, parallelize, deterministic,
                     cache, repeat):

    # Dataset from files list
    gen = tf.data.Dataset.from_tensor_slices(files)
    
    # Data loading
    gen = gen.map(lambda filename: 
                    map_parse_input(filename),
                    parallelize, deterministic)

    # Caching
    if cache:
        gen = gen.cache()
    
    # Preprocessing
    gen = gen.shuffle(len(files), reshuffle_each_iteration=True)
    gen = gen.map(lambda img, mask, gt: 
                    map_replace_background(img, mask, gt, bgs),
                    parallelize, deterministic)
    gen = gen.map(lambda img, gt: 
                    map_augmentation(img, gt, aug_prob, noises), 
                    parallelize, deterministic)
    gen = gen.map(lambda img, gt: 
                    map_preprocessing(img, gt), 
                    parallelize, deterministic)

    # Batching
    gen = gen.batch(batch_size, drop_remainder=True)
    
    # Oversampling
    gen = gen.repeat(repeat)

    # Prefetching
    if prefetch:
        gen = gen.prefetch(tf.data.experimental.AUTOTUNE)

    # Result
    return gen
\end{python}
\vspace{-0.5cm}
\begin{lstlisting}[frame=none,caption={Chosen \texttt{tf.data} input pipeline}, 
label=lst:tfdata_generator]
\end{lstlisting}


\subsection{Profiling}

As we have discussed, optimizations are crucial when working with complex input pipelines. We use TensorBoard \cite{tensorboard} to profile the training procedure and evaluate the actual improvements provided by our choices. The tool produces accurate statistics on CPU and GPU usage.

Table \ref{tab:data-generator-profiling} reports the performance summary for our three models, both with and without enabled optimizations. As expected, the improvement is clearly visible with the \texttt{CVPR} and the \texttt{CVPR Aug} models, but absent for the \texttt{Arena} model. In general, GPU Compute Time is equal to 63.5 ms in all cases. The main difference is observed for the Input Time between optimized and non-optimized alternatives.

\begin{table}[H]
	\caption{Training step time performance, profiled by TensorBoard}
	\label{tab:data-generator-profiling}
	\centering
	\begin{tabular}{|l|c|c||c|c||c|c|}
		\hline
		\textbf{Model} & \multicolumn{2}{|c||}{\textbf{Arena}} & \multicolumn{2}{|c||}{\textbf{CVPR}} & \multicolumn{2}{|c|}{\textbf{CVPR Aug}} \\
		\hline
		\textbf{Optimized} & \textbf{No} & \textbf{Yes} & \textbf{No} & \textbf{Yes} & \textbf{No} & \textbf{Yes} \\
		\hline
		Input Bound Percentage      &  0.3\% &  0.4\% & 35.7\% &  0.4\% & 46.9\% &  0.2\% \\
		GPU IDLE Percentage         & 12.5\% & 12.8\% & 42.7\% & 14.5\% & 53.0\% & 10.6\% \\
		\hline
		Total Step Time (ms)        &   72.8 &   72.4 &  110.8 &   74.1 &  135.6 &   70.9 \\
		Input Time (ms)             &    0.2 &    0.3 &   39.6 &    0.3 &   63.6 &    0.2 \\
		GPU Compute Time (ms)       &   63.8 &   63.2 &   63.5 &   63.5 &   63.7 &   63.5 \\
		%All Others Time (ms)        &    8.9 &    8.9 &    7.6 &   10.4 &    7.3 &   7.3 \\
		\hline
	\end{tabular}
\end{table}

For a better understanding, we also display TensorBoard visualizations for standard and optimized versions of the \texttt{CVPR Aug} model. Figure \ref{fig:profiling-cvpraug-summary} presents an overview of the performance over 35 training steps. The two charts clearly show how the non-optimized version is highly input-bound (46.9\%).

Also, Figure \ref{fig:profiling-cvpraug-gpu} shows the main tasks for which GPU and CPU are used during training. On GPU, the main difference regards the IDLE time. On the other hand, CPU computation of the optimized version mainly focuses on Albumentations while spreads over different tasks when no parallelization is used. This behavior is probably due to sequential non-prefetched operations that need a greater number of context switches between GPU and CPU, resulting in a waste of time.

\begin{figure}[!h]
	\begin{center}
		\begin{subfigure}[h]{0.47\textwidth}
			\centering
			\includegraphics[width=1\textwidth]{"contents/images/05-profiling-CVPRaug-std-summary"}
			\caption[]{Standard version}
		\end{subfigure}
		\hfill
		\begin{subfigure}[h]{0.47\textwidth}
			\centering
			\includegraphics[width=1\textwidth]{"contents/images/05-profiling-CVPRaug-opt-summary"}
			\caption[]{Optimized version}
		\end{subfigure}
	\end{center}
	\vspace{-0.5cm}
	\caption[Profiling: training performance summary of the \texttt{CVPR Aug} model]{Profiling: training performance summary of the \texttt{CVPR Aug} model}
	\label{fig:profiling-cvpraug-summary}
\end{figure}

\begin{figure}[!h]
	\begin{center}
		\begin{subfigure}[h]{0.49\textwidth}
			\centering
			\includegraphics[width=1\textwidth]{"contents/images/05-profiling-CVPRaug-std-gpu"}
			\caption[]{GPU, STANDARD VERSION}
		\end{subfigure}
		\hfill
		\begin{subfigure}[h]{0.49\textwidth}
			\centering
			\includegraphics[width=1\textwidth]{"contents/images/05-profiling-CVPRaug-opt-gpu"}
			\caption[]{GPU, OPTIMIZED VERSION}
		\end{subfigure}
		\vfill
	    \vspace{0.5cm}
		\begin{subfigure}[h]{0.49\textwidth}
			\centering
			\includegraphics[width=1\textwidth]{"contents/images/05-profiling-CVPRaug-std-cpu"}
			\caption[]{CPU, STANDARD VERSION (without IDLE)}
		\end{subfigure}
		\hfill
		\begin{subfigure}[h]{0.49\textwidth}
			\centering
			\includegraphics[width=1\textwidth]{"contents/images/05-profiling-CVPRaug-opt-cpu"}
			\caption[]{CPU, OPTIMIZED VERSION (without IDLE)}
		\end{subfigure}
	\end{center}
	\caption[Profiling: GPU and CPU main tasks utilization during \texttt{CVPR Aug} training]{Profiling: GPU and CPU main tasks utilization during \texttt{CVPR Aug} training}
	\label{fig:profiling-cvpraug-gpu}
\end{figure}




\section{Training}
\label{sec:implementation-training}

This section illustrates technical details about the training procedure. We firstly present chosen parameters, then provide time performance on the selected hardware. Please refer to Section \ref{sec:evaluation-training} in the next chapter for consulting training results.



\subsection{Settings}
\label{subsec:training-params}

\glsreset{mae}
\glsreset{adam}

As in the original paper from Mantegazza et al. \cite{mantegazza2019visionbased}, we use the \gls{mae} loss function and the \gls{adam} optimizer \cite{kingma2014adam} with the default learning rate of $0.001$ and automatic reducer on plateaus (4 epochs patience). The batch size is $64$, and the last 30\% of the training data (not shuffled) is used as a validation set.

The training runs for 60 epochs, without early stopping. The dataset is shuffled and repeated three times for each epoch to simulate an oversampling strategy, especially suited for the \texttt{CVPR} and the \texttt{CVPR Aug} models. The latter is trained with a prior augmentation probability of 95\%, as detailed in Section \ref{sec:implementation-imgaug}. Prefetching and parallelization \texttt{tf.data} parameters are automatically tuned by TensorFlow.



\clearpage
\subsection{Timing}
\label{subsec:training-timing}

While our first experiments on network interpretation and person masking have been conducted using Jupyter Notebooks on Google Colab, the training task has been carried out through classic Python scripts and executed on local machines.

\medskip

For debugging, we use a laptop with the following specifications:
\begin{itemize}
    \item OS Windows 10 Pro 64 bit
    \item CPU Intel Core i7-6700HQ quad-core @ 2.60 GHz
    \item GPU Nvidia GeForce GTX 950M (2 GB of dedicated memory)
    \item RAM 8 GB 2400MHz
\end{itemize}

The actual training is performed on a dedicated workstation available at \gls{idsia}:
\begin{itemize}
    \item OS Ubuntu 18.04 64 bit
    \item 2 CPUs Intel Xeon Gold 5217 octa-core @ 3 GHz
    \item 4 GPUs\footnote{please note that GPUs are used singularly, not for multi-GPU computing} Nvidia GeForce RTX 2080 Ti (11 GB of dedicated memory)
    \item RAM 128 GB 2666MHz
\end{itemize}

\medskip
    
On the specified hardware, the training procedure requires a different amount of time according to the model which is being trained. Considering the training parameters stated in \ref{subsec:training-params} and the three models alternatives presented in \ref{sec:model-variants}, we observe the following average performance.

\begin{itemize}
    \item \texttt{Arena} model takes 20 minutes with a 65-85\% of GPU utilization.
    \item \texttt{CVPR} model takes 40 minutes with a 50\% of GPU utilization.
    \item \texttt{CVPR Aug} model takes 120 minutes with a 20\% of GPU utilization.
\end{itemize}

All the models require 1724MiB/11019MiB of constant GPU memory usage.

Their training time is inversely proportional to GPU utilization since more data pre-processing operations, usually performed on CPU, also require a greater amount of time. As explained in Section \ref{subsec:data-generator-basic}, background replacement is implemented with TensorFlow and executed on GPU, thus only doubles the training time (compare the \texttt{Arena} and the \texttt{CVPR} models). On the contrary, Albumentations (hence the \texttt{CVPR Aug} model) does not benefit from GPU usage and has to be run on CPU, which is significantly slower than the former.



